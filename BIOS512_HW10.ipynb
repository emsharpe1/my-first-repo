{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d18cdd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency 'SnowballC'\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'SnowballC' successfully unpacked and MD5 sums checked\n",
      "package 'tokenizers' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\Ella Sharpe\\AppData\\Local\\Temp\\RtmpKKj4IV\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tokenizers' was built under R version 4.5.2\"\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tokenizers\")\n",
    "library(httr)\n",
    "library(tokenizers)\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0b649b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tokenize_text <- function(text) {\n",
    "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad33673",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "    paste(ngram, collapse=sep)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243368cf",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]\n",
    "        next_word <- tokens[i + n - 1L]\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6b3696",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "    tokens <- tokenize_text(text)\n",
    "    build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea9aa7e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "    res <- httr::GET(url)\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42736737",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "    keys <- ls(envir = tbl, all.names=TRUE)\n",
    "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys, 1)\n",
    "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04f6236",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c06b352",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "            start_words <- random_start(tbl, sep=sep)\n",
    "        }\n",
    "        word_sequence <- start_words\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "        paste(word_sequence, collapse= \" \")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99805555",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the king has forbidden me to marry another husband am not i shall ride upon"
     ]
    }
   ],
   "source": [
    "set.seed(2025)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)\n",
    "\n",
    "output <- gen3(start_words = c(\"the\", \"king\"), length = 15)\n",
    "\n",
    "cat(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814a43e",
   "metadata": {},
   "source": [
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3588349b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"and circumstances which beset us about waiting until the heavier vibrations were come no farther\"\n"
     ]
    }
   ],
   "source": [
    "url <- \"https://www.gutenberg.org/cache/epub/10662/pg10662.txt\"\n",
    "tbl <- digest_url(url, n=3)\n",
    "gen <- make_ngram_generator(tbl, n=3)\n",
    "\n",
    "print(gen(length=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985e40a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the king is also defective you may demand a refund of any kind express or"
     ]
    }
   ],
   "source": [
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "tbl1 <- digest_url(url, n=3)\n",
    "gen1 <- make_ngram_generator(tbl1, n=3)\n",
    "\n",
    "output <- gen1(start_words = c(\"the\", \"king\"), length = 15)\n",
    "\n",
    "cat(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d967da",
   "metadata": {},
   "source": [
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c41612fb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"utter warm and dry the bandages that she saw me not greatly nor to breathe\"\n"
     ]
    }
   ],
   "source": [
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "tbl2 <- digest_url(url, n=3)\n",
    "gen2 <- make_ngram_generator(tbl2, n=3)\n",
    "\n",
    "print(gen(length=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326cf2c6",
   "metadata": {},
   "source": [
    "The content generated from Grimm's Fairy Tales seems to have more flowery wording than that of the Ancient Armour and Weapons in Europe. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc917e5",
   "metadata": {},
   "source": [
    "A language learning model is a model based on some body of text that uses that text to predict the next word in a sequence. In short, it is a probability distribution over words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b63fc7",
   "metadata": {},
   "source": [
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb8630b",
   "metadata": {},
   "source": [
    "To run a language model locally, you can download Ollama to run an open access language model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | The shell around the OS allows you to interact with all functions of the system, such as interpreting commands like mkdir project |\n",
    "| **Terminal emulator** | The terminal emulator is what hosts the shell and allows you to interact with it: it provides the interface where you type mkdir project. |\n",
    "| **Process** | Something running on the computer, such as the mkdir program. |\n",
    "| **Signal** | Things to send to processes for them to do something |\n",
    "| **Standard input** | Reads characters from the input |\n",
    "| **Standard output** | Writes the normal output for a program|\n",
    "| **Command line argument** | Things that we can pass to a process when we start it|\n",
    "| **The environment** | All of the things a process can see when it is running |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147631be",
   "metadata": {},
   "source": [
    "The programs are find, xargs, and grep. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcd735",
   "metadata": {},
   "source": [
    "#### b) Explain what this command is doing, part by part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba43431b",
   "metadata": {},
   "source": [
    "This command is finding everywhere a particular function is mentioned in a project. Find is searching for files that end in \".R.\" Then, the pipe operator is connecting find to xargs which allows us to search each individual file with grep. Grep allows the command to search for things in the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f542518",
   "metadata": {},
   "source": [
    "$ docker run hello-world\n",
    "Unable to find image 'hello-world:latest' locally\n",
    "latest: Pulling from library/hello-world\n",
    "17eec7bbc9d7: Pull complete\n",
    "Digest: sha256:56433a6be3fda188089fb548eae3d91df3ed0d6589f7c2656121b911198df065\n",
    "Status: Downloaded newer image for hello-world:latest\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
    "    (amd64)\n",
    " 3. The Docker daemon created a new container from that image which runs the\n",
    "    executable that produces the output you are currently reading.\n",
    " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
    "    to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    " $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    " https://hub.docker.com/\n",
    "\n",
    "For more examples and ideas, visit:\n",
    " https://docs.docker.com/get-started/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b80d7ca",
   "metadata": {},
   "source": [
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ca53dc",
   "metadata": {},
   "source": [
    "$ docker run -it -p 8787:8787 rocker/verse\n",
    "[s6-init] making user provided files available at /var/run/s6/etc...exited 0.\n",
    "[s6-init] ensuring user provided files have correct perms...exited 0.\n",
    "[fix-attrs.d] applying ownership & permissions fixes...\n",
    "[fix-attrs.d] done.\n",
    "[cont-init.d] executing container initialization scripts...\n",
    "[cont-init.d] 01_set_env: executing...\n",
    "skipping /var/run/s6/container_environment/HOME\n",
    "skipping /var/run/s6/container_environment/RSTUDIO_VERSION\n",
    "[cont-init.d] 01_set_env: exited 0.\n",
    "[cont-init.d] 02_userconf: executing...\n",
    "\n",
    "\n",
    "The password is set to phai6mah2pheTh8f\n",
    "If you want to set your own password, set the PASSWORD environment variable. e.g. run with:\n",
    "docker run -e PASSWORD=<YOUR_PASS> -p 8787:8787 rocker/rstudio\n",
    "\n",
    "\n",
    "[cont-init.d] 02_userconf: exited 0.\n",
    "[cont-init.d] done.\n",
    "[services.d] starting services\n",
    "[services.d] done.\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\n",
    "^C[cont-finish.d] executing container finish scripts...\n",
    "[cont-finish.d] done.\n",
    "[s6-finish] waiting for services.\n",
    "s6-svwait: fatal: timed out\n",
    "[s6-finish] sending all processes the TERM signal.\n",
    "TTY detected. Printing informational message about logging configuration. Logging configuration loaded from '/etc/rstudio/logging.conf'. Logging to 'syslog'.\n",
    "malloc_consolidate(): unaligned fastbin chunk detected\n",
    "[s6-finish] sending all processes the KILL signal and exiting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e523fd",
   "metadata": {},
   "source": [
    "#### c) How do you log in to the RStudio server?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4da7c",
   "metadata": {},
   "source": [
    "You log into the RStudio server by going to http://localhost:8787 and entering the username (rstudio) and given password (phai6mah2pheTh8f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
